# 10.1

（00:00 - 01:33）是上一个lab的抽查问答，与内容无关故跳过。

今天的课程的内容是锁。你们或许在其他的课程中已经学习过锁，这节课偏向于理论介绍，并且或许会与其他课程中有关锁的内容有些重合，不过这节课更关注内核和操作系统中的锁。

首先，我们来回顾一下，为什么我们需要锁？故事要从应用程序想要使用多个CPU核开始，使用多个CPU核可以带来性能的提升。如果一个应用程序运行在多个CPU核上，并且执行了系统调用，那么内核需要能够处理并行的系统调用。如果系统调用并行的在多个CPU核上运行，那么它们可能会并行的访问共享的数据结构。到目前为止，你们也看到了XV6有很多共享的数据结构，例如proc，ticks，之后我们还会看到buffer cache等等。如果并行的访问数据结构，例如一个核在读取数据，另一个核在写入数据，我们需要使用锁来协调对于共享数据的更新，这样数据可以保持一致性。所以，我们需要锁来控制并确保数据共享是正确的。

但是现在的处境有些令人失望，因为我们想要通过并行来获得高性能，我们想要并行的在不同的CPU核上执行系统调用，但是如果这些系统调用使用过了共享的数据，我们又需要使用锁，而锁会将这些系统调用串行执行，所以最后锁又限制了性能。

![](../.gitbook/assets/image%20%28446%29.png)

所以现在我们处于一个矛盾的处境，出于正确性，我们需要使用锁，但是考虑到性能，锁又是极不好的。这就是现实，我们接下来会看看如何改善这个处境。

以上是一个整体的介绍，但是回到最开始，为什么应用程序一定要使用多个CPU核来提升性能呢？这个实际上与过去几十年技术的发展有关。下面这张经典的图可以解释为什么。

![](../.gitbook/assets/image%20%28445%29.png)

这张图有点复杂，X轴是时间，Y轴是单位，具体意义取决于特定的曲线。这张图中的核心是，在过去的几十年


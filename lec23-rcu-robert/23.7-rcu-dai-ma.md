# 23.7 RCU代码

为了巩固前面介绍的内容，接下来看一段使用了RCU的简单代码。上半段是读取被RCU保护的链表 ，下半段代码是替换链表的第一个元素。

![](../.gitbook/assets/image%20%28711%29.png)

数据读取位于rcu\_read\_lock和rcu\_read\_unlock之间，这两个函数几乎不做任何事情。rcu\_read\_lock会设置一个标志位，表明如果发生了定时器中断，请不要执行context switch，因为我正在RCU critical 区域中。所以rcu\_read\_lock会设置一个标志位来阻止定时器中断导致的context switch，中断或许还会发生，但是不会导致context switch。rcu\_read\_unlock取消该标志位。所以这是一个集成在RCU critical区域的计数器。rcu\_read\_lock和rcu\_read\_unlock因为几乎不做任何工作所以极其的快。

其中的while循环会扫描链表，rcu\_dereference函数会插入memory barrier，它首先会从内存中拷贝e，触发一个memory barrier，之后返回指向e的指针。之后我们就可以读取e指针指向的数据内容，并走向下一个链表元素。数据读取部分非常简单。

数据写入部分更复杂点。RCU并不能帮助数据写入者之间避免相互干扰，所以必须有一种方法能确保一次只能有一个数据写入者更新链表。这里我们假设我们将使用普通的spinlock，所以最开始数据写入者获取锁。如果我们要替换链表的第一个元素，我们需要保存先保存链表第一个元素的拷贝，因为最后我们需要释放它，所以有old=head。接下来的代码执行的是之前介绍的内容，首先是分配一个全新的链表元素，之后是设置该链表元素的内容，设置该链表元素的next指针指向旧元素的next指针。之后的rcu\_assign\_pointer函数会设置一个memory barrier，以确保之前的所有写操作都执行完，之后再将head指向新分配的链表元素e。之后就是释放锁。

之后调用synchronize\_rcu确保任何一个可能持有了旧的链表元素的CPU都执行一次context switch，因此这些CPU会放弃指向旧链表元素的指针。最后是释放旧的链表元素。

这里有件事情需要注意，在数据读取代码中，我们可以在循环中查看链表元素，但是我们不能将链表元素返回。例如，我们使用RCU的时候，不能写一个list\_lookup函数来返回链表元素或者返回指向链表元素中数据的指针，也就是嵌入在链表元素中的字符串。我们必须只在RCU critical区域内查看被RCU保护的数据，如果我们写了一个通用的函数返回链表元素，或许我们能要求这个函数的调用者也遵循一些规则，但是函数的调用者还是可能会出发context switch，并且我们在函数的调用者返回之前调用了rcu\_read\_unlock，这是非法的因为现在定时器中断可以迫使context switch。所以使用RCU的确会向数据读取者增加一些之前并不存在的限制。

> 学生提问：这样是不是说，如果我们不可能返回下标是i的元素所包含的内容？
>
> Robert教授：可以返回一个拷贝，如果e-&gt;x是个字符串，那么我们可以返回一个该字符串的拷贝，这是没有问题的。但是如果我们直接返回一个指针指向e-&gt;x，那就违反了RCU规则。实际上返回e中的任何指针都是错误的，因为我们不能在持有指向RCU保护数据的指针时，发生context switch。这里的风格是直接在RCU critical区域使用这些数据。

接下来我将再简短的介绍性能。如果你使用RCU，数据读取非常的快，除了读取数据本身的开销之外就没有别的额外的开销了。如果你的链表有10亿个元素，读取链表本身就要很长的时间，但是这里的时间消耗并不是因为同步（注，也就是类似加锁等操作）引起的。所以你几乎可以认为RCU对于数据读取者来说没有额外的负担。唯一额外的工作就是在rcu\_read\_lock和rcu\_read\_unlock里面设置好不要触发context switch，并且在rcu\_dereference中设置memory barrier，这些可能会消耗几十个CPU cycle，但是相比锁来说代价要小的多。

对于数据写入者，性能会更加的糟糕。首先之前使用锁的时候的所有工作仍然需要做，例如获取锁和释放锁。其次，现在还有了一个可能非常耗时的synchronize\_rcu函数调用。实际上在synchronize\_rcu内部会出让CPU，所以代码在这不会消耗CPU等待，但是它可能会消耗大量时间来等待其他所有的CPU核完成context switch。所以基于数据写入时的多种原因，和数据读取时的工作量，性能提升非常大，如果数据读取区域很短的话，并且数据写入并没有很多，那么数据写入或许会很慢也没关系。所以当人们将RCU应用到内核中时，必须要做一些性能测试来确认使用RCU是否能带来好处，因为这实际取决与工作负载。

> 70:00 - 73:20（不相关的问题，故略过）

你们应该已经看到了RCU并不是广泛通用的，你不能把所有使用spinlock并且性能很差的场景转化成使用  
RCU，并获得更好的性能，主要的原因是RCU完全帮不到写操作，甚至会让写操作更慢，只有当读操作远远多于读操作时才有可能应用RCU。RCU有这样的限制，代码不能在sleep的时候持有指针指向被RCU保护的数据，这会使得一些代码非常奇怪，当一定要sleep的时候，在sleep之后需要重新进入RCU critical区域再次查找之前已经看过的数据，如果这些数据还存在的话。所以RCU使得代码稍微复杂了一些。

另一方面可以直接应用RCU的数据结构在更新时，需要能支持单个committing write操作。你不能在原地更新数据，而是必须创建一个新的元素对象带代替之前的元素对象。所以单链表，树是可以应用RCU的数据结构，但是一些复杂的数据结构不能直接使用RCU。[论文](https://pdos.csail.mit.edu/6.828/2020/readings/rcu-decade-later.pdf)里面提到了一些更复杂的方法，例如sequence lock，可以允许原地更新数据的同时，又不用数据读取者使用锁。但是这些方法要复杂一些，并且能够提升性能的场景也是受限的。

另一个小问题是，并没有明确的时间点表明数据读取者仍然能看到旧的数据，因为如果某些数据读取者在数据写入者替换之前，获取了一个指针指向被RCU保护的数据，数据读取者可能会在较长的时间内持有这个数据。大部分时候这都无所谓，但是论文提到了一些场景人们期望写操作在完成时立即生效，这时读到旧数据会有点让人感到意外。

作为一个独立的话题，你们或许会想对于一个写操作频繁的数据改如何提升性能。RCU只关心读操作频繁的数据，但是这类数据只代表了一种场景。在一些特殊场景中，写操作频繁的数据也可以获取好的性能，但是我还不知道存在类似RCU这样通用的方法能优化写操作频繁的数据。但是仍然存在一些思路可以处理写操作频繁的数据。最有效的方法就是重新构造你的数据结构，这样它就不是共享的。有的时候共享数据完全是没必要的，一旦你发现共享是个问题，你可以让数据不共享。


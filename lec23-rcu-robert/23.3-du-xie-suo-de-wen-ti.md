# 23.3 读写锁的问题

> 学生提问：如果开始有一堆数据读取者在读，之后来了一个数据写入者，但是又有源源不断的数据读取者加入进来，是不是就轮不到数据写入者了？
>
> Robert教授：如果多个数据读取者获取了锁，每一个都会通过CAS指令将n加1，现在n会大于0。如果这时一个数据写入者尝试要获取锁，它的CAS指令会将n与0做对比，只有当n等于0时，才会将其设置为-1。但是因为存在多个数据读取者，n不等于0，所以CAS指令会失败。数据写入者会在w\_lock的循环中不断尝试并等待n等于0，如果存在大量额数据读取者，这意味着数据写入者有可能会一直等待。这是这种锁机制的一个缺陷。

> 学生提问：在刚刚两个数据读取者要获取锁的过程中，第二个数据读取者需要再次经历一次循环，这看起来有点浪费，如果放到了多个数据读取者，那么它们都需要重试。
>
> Robert教授：你说到了人们为什么不喜欢这种锁的点子上了。即使没有任何的数据写入者，但是在多个CPU核上有大量的数据读取者，r\_lock也可能会有非常高的代价。在一个多核的系统中，每个CPU核都有一个关联的cache，也就是L1 cache。每当CPU核读写数据时，都会保存在cache中。除此之外，还有一些线路使得CPU可以彼此交互，因为如果某个CPU核写了某个数据，它需要告诉其他的CPU核不要去缓存这个数据，这被称为invalidation。

![](../.gitbook/assets/image%20%28692%29.png)

> 如果有多个数据读取者在多个CPU上同时调用r\_lock，它们都会读取读写锁的计数l-&gt;n，并将这个数据加载到CPU的cache中，它们也都会调用CAS指令，但是第一个调用CAS指令的CPU会修改l-&gt;n的内容。作为修改的一部分，它需要使得其他CPU上的cache失效。所以执行第一个CAS指令的CPU需要通过线路发送invalidate消息给其他每一个CPU核，之后其他的CPU核在执行CAS指令时，需要重新读取l-&gt;n，但是这时CAS指令会失败，因为l-&gt;n已经等于1了，但是x还是等于0。之后剩下的所有读取者会回到循环的最开始，重复上面的流程，但是还是又有一个数据读取者能成功。
>
> 假设有n个数据读取者，那么每个r\_lock平均需要循环n/2次，每次循环都涉及到O\(n\)级别的CPU消息，因为每次至少所有CPU中对于l-&gt;n的cache需要被设置为无效。这意味着，对于n个CPU核来获取一个锁的成本是O\(n^2\)，当你为一份数据增加CPU核时，成本以平方增加。
>
> 这是一个非常糟糕的结果，因为你会期望如果有10个CPU核完成一件事情，你将获得10倍的性能，尤其现在还只是读数据并没有修改数据。你期望它们能真正的并行运行，当有多个CPU核时，每个CPU核读取数据的时间应该与只有一个CPU核时读取数据的时间一致，这样并行运行才有意义，因为这样你才能同时做多件事情。但是现在，越多的CPU核尝试读取数据，每个CPU核获取锁的成本越高。
>
> 对于一个只读数据，如果数据只在CPU的cache中的话，它的访问成本可能只要几十个CPU cycle。但是如果数据很受欢迎，由于O\(n^2\)的效果，光是获取锁就要消耗数百甚至数千个CPU cycle，因为不同CPU访问修改数据需要经过通过CPU之间的连线来完成缓存一致操作。
>
> 所以这里的读写锁，将一个原本成本很低的读操作，因为要读写锁的l-&gt;n，变成了一个成本极其高的操作。如果你要读取的数据本身就很简单，这里的锁可能会完全摧毁任何可能的并行带来的性能提升。

读写锁糟糕的性能是RCU存在的原因，因为如果读写锁足够有效，那么就没有必要做的更好。除了在有n个CPU核时，r\_lock的成本是O\(n^2\)之外，这里的读写锁将一个本来可以缓存在CPU中的，并且可能会很快的只读的操作，变成了需要写锁的计数器l-&gt;n的操作。如果我们写的是可能与其他CPU核共享的数据，写操作通常会比读操作成本高得多。因为读一个未被修改的数据可以在几个CPU cycle内就从CPU cache中读到，但是修改可能被其他CPU核缓存的数据，需要涉及CPU核之间的通信来使得缓存失效。不论任何安排数据，任何涉及到更改共享数据的操作对于性能来说都是灾难。

![](../.gitbook/assets/image%20%28701%29.png)

所以r\_lock中最关键的就是它对共享数据做了一次写操作。所以我们期望找到一种方式能够在读数据的同时，又不需要写数据，哪怕是写锁的计数器也不行。这样读数据实际上才是一个真正的只读操作。


# 23.1

今天的话题是如何在多核CPU计算机上获得好的性能，这是一个非常有趣，深入且令人着迷的话题。今天我们只会涉及这个话题的很小的一个部分，也就是如何在面对内核中经常读而不经常写的共享数据时，获得更好的性能。在不同的场景有不同的方法可以在多核CPU的机器上获得好的性能，我们今天要看的是Linux的RCU，它是一种对于read-heavy内核数据非常成功的方法。

这里的背景是，如果你有一个现代的计算机，或许包含了4、8、16、64个并行运行的CPU核，这些CPU核共享了内存数据，内核将会是一个并行运行的程序。如果你想要获得好的性能，你需要确保内核能尽可能的在多个CPU核上并行的完成它的工作。如果你能将内核并行的运行在8个CPU核上，并且它们都能完成有效的工作，那么相比运行在单个CPU核上，你就能获得8倍的性能。从理论上来说，这明显是可能的。如果你在内核中有大量的进程，那么我们就不太用担心，它们极有可能是并行运行的，内核也不用做任何额外的工作。如果你有很多应用程序都在执行系统调用，很多时候，不同的应用程序执行的不同系统调用看起来应该是相互独立的，并且在很多场景下应该在不相互影响的前提下运行。例如，通过fork产生的两个进程，或者读取不同pipe的两个进程，或者读写不同文件的两个进程，并没有明显的原因表明不同的进程之间会相互影响，为什么不同的进程不能并行的运行并获得n倍的吞吐量。

但是问题是内核中包含了大量的共享数据。出于一些其他的原因，内核共享了大量的资源，例如内存，CPU，磁盘缓存，inode缓存，这些东西都在后台被不同的进程所共享。这意味着，即使两个完全不相关的进程在执行两个系统调用，如果这两个系统调用需要分配内存或使用磁盘缓存或者涉及到线程调度决策，它们可能最终会使用内核中的数据结构，因此我们需要有办法能让它们在使用相同数据时，又互不影响。

在许多年中都有巨大的努力来让内核中的这些场景能更快的运行。我们之前看过其中一种为了保证正确性的方法，也就是spinlock。spinlock很直观，它的工作就是当两个进程可能会相互影响时，阻止并行运行。所以spinlock的直接效果就是降低性能。它使得正确性更有了保障，但是又绝对的阻止了并行执行，这并不总是能令人满意。

今天我们会关注read-heavy数据，也就是说你的数据主要是被读，相对来说很少被写，我将使用单链表来作为主要的例子。对于单链表，会存在一个指向头指针（head）的全局变量，之后是一些链表元素，每个链表元素都包含了一个数据，假设是字符串。第一个链表元素包含了“hello”。每个链表元素还包含了一个next指针，指向了下一个链表元素。

